# number of runs of continuation method runs
n_continuation = 1
# number of points that hopefully belong to the pareto front for grad continuation
n_pareto = 25
# number of points that hopefully belong to the pareto front for prox continuation
n_pareto = 18
# numper of iterations for prediction for loss
n_predictor = 7
# number of training epochs for corrector for loss
n_corr = 20
# numper of iterations for prediction for l1-norm
n_predictor = 7
# number of training epochs for corrector for l1-norm
n_corr = 20
# number of training epochs for first run
n_corr_first = 500

Training loss after start iteration = 0.08882935345172882
Validation loss after start iteration = 0.1410769820213318
Test loss after start iteration = 0.14434966444969177
L1 norm after start iteration = 6.062563896179199
Training accuracy after start iteration = 97.63571428571429
Testing accuracy after start iteration = 95.62857142857143

Training loss after grad continuation = 0.08043045550584793
Validation loss after grad continuation = 0.14023570716381073
Test loss after grad continuation = 0.14218202233314514
L1 norm after grad continuation = 6.361047267913818
Training accuracy after grad continuation = 97.88214285714285
Testing accuracy after grad continuation = 95.8

Training loss after prox continuation = 0.9380689263343811
Validation loss after prox continuation = 0.9401327967643738
Test loss after prox continuation = 0.9308914542198181
L1 norm after prox continuation = 0.919922411441803
Training accuracy after prox continuation = 75.75
Testing accuracy after prox continuation = 76.68571428571428

Total computation time for deterministic Train/Test = 723.7643127441406

